{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arham-12336/Final_evaluation/blob/main/Final_Evaluation_notebook_04_2_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q9md00S9x6D"
      },
      "source": [
        "# Importing the Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5ZNKyna8Gy6",
        "outputId": "4116d21d-d382-41ea-b008-f90ad6d14f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyg-lib\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.16)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (0.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric) (21.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "\n",
        "!pip install pyg-lib\n",
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8R1LcodNSH7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import collections, numpy\n",
        "import collections, numpy\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive\n",
        "import os\n",
        "from torch.utils.data.dataloader import T\n",
        "import pickle\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import linear_model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from pandas.core.common import random_state\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from scipy.linalg import sqrtm \n",
        "from scipy.special import softmax\n",
        "import networkx as nx\n",
        "# import copy\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "# from torch_geometric.utils import degree,structured_negative_sampling\n",
        "# from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "# from torch_geometric.nn.conv import MessagePassing\n",
        "# from torch_geometric.typing import Adj\n",
        "import torch\n",
        "from torch import nn,optim,Tensor\n",
        "# from torch_sparse import SparseTensor,matmul\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics,preprocessing\n",
        "import time\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# import os\n",
        "# import torch\n",
        "# from torch_geometric.nn import MetaPath2Vec\n",
        "# import pandas as pd\n",
        "# import pickle\n",
        "# import numpy as np\n",
        "# import networkx as nx\n",
        "# from torch_geometric.data import HeteroData\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV3UMupgOhv0",
        "outputId": "c3d9bcc7-8c9a-4d07-ea8e-e0e0f68a6018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cR9anSMA336"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/FYP (Application of Graph embeddings)/Final/Experiments/IND2new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9W5M-wXQPRN",
        "outputId": "f8a7f09d-ab05-4a84-baf5-f8e177a16b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1985COCI2015.pkl      Author.graph  HeteroData.pt      venCent.pkl\n",
            "1985COCIFull2015.pkl  Author.hash   pubCent.pkl        Venue.graph\n",
            "1985metadata2015.pkl  Author.info   Publication.graph  Venue.hash\n",
            "autCent.pkl           DOIs.pkl      Publication.hash   Venue.info\n",
            "autCOCILst.pkl        DOItest.pkl   Publication.info\n",
            "autCOCI.pkl           FMat.pkl      refDf.pkl\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqST6yvQCQHG"
      },
      "outputs": [],
      "source": [
        "\n",
        "usecase=\"IND2new\" \n",
        "\n",
        "'''\n",
        "NEW: Literature review 2021\n",
        "BIB1: Bibliometric Study with seminal seed DOIs\n",
        "BIB2: Bibliometric Study with random seed DOIs\n",
        "IND1: Indicators Review with seminal seed DOIs\n",
        "IND2: Indicators Review with random seed DOIs\n",
        "COM: Community Review with random seed DOIs\n",
        "'''\n",
        "\n",
        "#Date range\n",
        "if usecase[0:3]==\"BIB\":\n",
        "    start_year = 2010\n",
        "    end_year = 2020\n",
        "elif usecase[0:3]==\"IND2new\":\n",
        "    start_year = 1985\n",
        "    end_year = 2015\n",
        "elif usecase[0:3]==\"COM_NEW\":\n",
        "    start_year = 1970\n",
        "    end_year = 2009\n",
        "else:\n",
        "    start_year = 1970\n",
        "    end_year = 2020\n",
        "\n",
        "usecaseDIR= \"/\"+usecase+\"/\"\n",
        "\n",
        "citNet = \"1985COCI2015.pkl\"\n",
        "metadata = \"1985metadata2015.pkl\"\n",
        "\n",
        "autCitNet = \"autCOCI.pkl\"\n",
        "autCitNetLst = \"autCOCILst.pkl\"\n",
        "\n",
        "pubCentPkl = \"pubCent.pkl\"\n",
        "autCentPkl = \"autCent.pkl\"\n",
        "venCentPkl = \"venCent.pkl\"\n",
        "\n",
        "DOIPkl = \"DOIs.pkl\"\n",
        "DOItestPkl = \"DOItest.pkl\"\n",
        "refDf = \"refDf.pkl\"\n",
        "\n",
        "FMatPkl = \"FMat.pkl\"\n",
        "ptHeteroData = \"HeteroData.pt\"\n",
        "\n",
        "\n",
        "PublicationGraph =\"Publication.graph\"\n",
        "PublicationHash = \"Publication.hash\"\n",
        "\n",
        "VenueGraph = \"Venue.graph\"\n",
        "VenueHash = \"Venue.hash\"\n",
        "\n",
        "AuthorGraph =\"Author.graph\"\n",
        "AuthorHash = \"Author.hash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QGQSkjZtFufB",
        "outputId": "f09558b1-b5ad-4fdc-d62e-024e37d67222"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'autCOCI.pkl'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autCitNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8DQVu-UOFL3"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPAqdbO5_lDY"
      },
      "outputs": [],
      "source": [
        "def features_selection(Feature_Mat):\n",
        "  X =Feature_Mat.iloc[:,1:48].values\n",
        "  y =Feature_Mat.iloc[:,48].values\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  rf = RandomForestRegressor(n_estimators=150)\n",
        "  rf.fit(X_train, y_train)\n",
        "  sort = rf.feature_importances_.argsort()\n",
        "  # # plt.barh(Feature_Mat.columns[sort], rf.feature_importances_[sort],align='center')\n",
        "  # plt.xlabel(\"Feature Importance\")\n",
        "  Features=Feature_Mat.columns[sort]\n",
        "  return Features\n",
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XeJhWLGTeYP"
      },
      "outputs": [],
      "source": [
        "Feature_Mat_IND=pd.read_pickle('FMat.pkl')\n",
        "set1=features_selection(Feature_Mat_IND)\n",
        "Feature_Mat_COM=pd.read_pickle('FMat_COM.pkl')\n",
        "set2=features_selection(Feature_Mat_COM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2BsgLLdOhJd"
      },
      "source": [
        "# Machine Learning on Feature Matrix\n",
        "We have utilized different Machine Learning algorithms to become more accurate at predicting outcomes to our feature matrix data frame. In this notebook we  have implement different machine learning algorithms and results obtained on our 2 data frames obtained through finding different centrality features for different articles. The first data frame contains 6146 rows and the second data frame has 95136 rows both have same no features (48) along with the annotated label (True/False).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob2yeAZxVW16"
      },
      "outputs": [],
      "source": [
        "Feature_mat=pd.concat([Feature_Mat_IND, Feature_Mat_COM])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nIuAD-nPQHg"
      },
      "source": [
        "### Approach I\n",
        "In this approach we have used the Feature [importance function](https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285) on Random forest to identify the important features (network-based).We have used top 30 features predicted as important for the IND feature matrix. We firstly combine both the dataframe IND and COM.Combinely they have 101282 rows with 30 features and 1 labeled column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtUvRrPjOghl"
      },
      "outputs": [],
      "source": [
        "Features=Feature_mat[['ACC_Actd_','BC_Pctd_','Auth_Vctg_','IN_Pctg_','PR_Vctg_','PR_Actd_','Hub_Vctg_','PR_Pctg_','Auth_Pctg_',\n",
        " 'Hub_Vctd_','IN_Vctd_','BC_Vctg_','ACC_Vctg_','CC_Pctd_','IN_Actg_','IN_Vctg_','Hub_Actg_','OUT_Vctg_','PR_Pctd_','OUT_Pctg_',\n",
        " 'Auth_Actg_','BC_Actg_','CC_Pctg_','CC_Vctg_','OUT_Actg_','PR_Actg_','ACC_Pctg_','ACC_Actg_','BC_Pctg_','Hub_Pctd_','y']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYMDCdYNXNG7"
      },
      "source": [
        "### Approach II:\n",
        "In this approach we have used the Feature [importance function](https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285) on Random forest to identify the important features (network-based).We have used top 30 features predicted as important for the COM feature matrix. We firstly combine both the dataframe IND and COM.Combinely they have 101282 rows with 30 features and 1 labeled column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbI5GLPDXEgV"
      },
      "outputs": [],
      "source": [
        "Features=Feature_mat[['IN_Vctg_','Auth_Pctd_','Auth_Pctg_','Hub_Vctg_','PR_Vctg_','Hub_Pctg_','BC_Pctd_','ACC_Actd_','CC_Vctg_',\n",
        " 'Auth_Actg_','Hub_Actg_','BC_Vctg_','Auth_Actd_','CC_Pctd_','PR_Actd_','CC_Vctd_','CC_Pctg_','PR_Pctg_','ACC_Vctg_','PR_Actg_',\n",
        " 'BC_Actd_','CC_Actg_','ACC_Actg_','BC_Actg_','Hub_Pctd_','OUT_Actg_','OUT_Vctg_','ACC_Pctg_','BC_Pctg_','OUT_Pctg_','y']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcaX_xsAXwfZ"
      },
      "source": [
        "### Approach III:\n",
        "In this approach we have used the Feature importance function [1] on Random forest to identify the important features (network-based).We have used 24 features which were common in both  feature matrices. We firstly combine both the dataframe IND and COM.Combinely they have 101282 rows with 24 features and 1 labeled column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kQGgrVXXvIB"
      },
      "outputs": [],
      "source": [
        "Features=Feature_mat[['ACC_Actd_', 'BC_Pctd_', 'PR_Vctg_', 'PR_Actd_', 'Hub_Vctg_', 'PR_Pctg_', 'Auth_Pctg_', 'BC_Vctg_', 'ACC_Vctg_', 'CC_Pctd_', 'IN_Vctg_', 'Hub_Actg_', 'OUT_Vctg_', 'OUT_Pctg_', 'Auth_Actg_', 'BC_Actg_', 'CC_Pctg_', 'CC_Vctg_', 'OUT_Actg_', 'PR_Actg_', 'ACC_Pctg_', 'ACC_Actg_', 'BC_Pctg_', 'Hub_Pctd_','y']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqqbuadfV_2a"
      },
      "outputs": [],
      "source": [
        "def ML_on_FMat(Features):\n",
        "  X =Features.iloc[:,1:30].values\n",
        "  y = Features.iloc[:,30].values\n",
        "  folds=StratifiedKFold(n_splits=5)\n",
        "  scores_logistic=[]\n",
        "  score_svm=[]\n",
        "  score_random_forest=[]\n",
        "  score_naive_bayes=[]\n",
        "  score_knn=[]\n",
        "  score_decision_tree=[]\n",
        "  i=1\n",
        "  def get_score(model,X_train,X_test,y_train,y_test):\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "#     get_roc(model,y_pred,y_test)\n",
        "#     return metrics.roc_auc_score(y_test, y_pred)\n",
        "    return metrics.f1_score(y_test, y_pred)\n",
        "\n",
        "  for train_index,test_index in folds.split(X,y):    \n",
        "    print(\"Split number: \",i)\n",
        "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], \\\n",
        "                                       y[train_index], y[test_index]\n",
        "    scores_logistic.append(get_score(LogisticRegression(solver='lbfgs', max_iter=1000),X_train,X_test,y_train,y_test))\n",
        "    score_svm.append(get_score(SVC(),X_train,X_test,y_train,y_test))\n",
        "    score_random_forest.append(get_score(RandomForestClassifier(n_estimators=50,random_state=0),X_train,X_test,y_train,y_test))\n",
        "    score_naive_bayes.append(get_score(GaussianNB(),X_train,X_test,y_train,y_test))\n",
        "    score_knn.append(get_score(KNeighborsClassifier(3),X_train,X_test,y_train,y_test))\n",
        "    score_decision_tree.append(get_score(DecisionTreeClassifier(),X_train,X_test,y_train,y_test))\n",
        "    \n",
        "    i=i+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgFGgq2EV_zY",
        "outputId": "5a39a968-3d60-4601-e0e1-c123724166c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split number:  1\n",
            "Split number:  2\n",
            "Split number:  3\n",
            "Split number:  4\n",
            "Split number:  5\n"
          ]
        }
      ],
      "source": [
        "ML_on_FMat(Features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jgDbht46lOj"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cP8p5oWO6j5d"
      },
      "outputs": [],
      "source": [
        "def train_test_ML2(dataset, dataform, X_train, y_train, X_test, y_test):\n",
        "    temp_df = pd.DataFrame(columns=['Data Set', 'Data Form', 'Dimensions', 'Model', 'Accuracy', 'F1 Score', 'Recall', 'Precision','Actual Labels','predicted Labels','Time Taken'])\n",
        "    for i in [LogisticRegression(solver='lbfgs', max_iter=1000), KNeighborsClassifier, SVC, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier]:\n",
        "        start_time = time.time()\n",
        "        reg = i().fit(X_train, y_train)\n",
        "        y_pred = reg.predict(X_test)\n",
        "        accuracy = np.round(accuracy_score(y_test, y_pred), 2)\n",
        "        f1 = np.round(f1_score(y_test, y_pred, average='weighted'), 2)\n",
        "        recall = np.round(recall_score(y_test, y_pred, average='weighted'), 2)\n",
        "        precision = np.round(precision_score(y_test, y_pred, average='weighted'), 2)\n",
        "        actual_labels=y_test.value_counts()\n",
        "        end_time = time.time()\n",
        "        time_taken = np.round((end_time - start_time), 2)\n",
        "        y_pred = pd.DataFrame(y_pred)\n",
        "        predicted_labels=y_pred.value_counts()\n",
        "        temp_df.loc[len(temp_df)] = [dataset, dataform, X_train.shape[1], str(i).split('.')[-1][:-2], accuracy, f1, recall, precision,actual_labels.tolist(),predicted_labels.tolist(),time_taken]\n",
        "    return temp_df\n",
        "\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(5,2),max_iter = 300,activation = 'relu',solver = 'adam')\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(48,10,2),max_iter = 300,activation = 'relu',solver = 'adam')\n",
        "def MLP(dataset, dataform, X_train, y_train, X_test, y_test):\n",
        "  temp_df = pd.DataFrame(columns=['Data Set', 'Data Form', 'Dimensions', 'Model', 'Accuracy', 'F1 Score', 'Recall', 'Precision','Actual Labels','predicted Labels','Time Taken'])\n",
        "  start_time = time.time()\n",
        "  reg = mlp_clf.fit(X_train, y_train)\n",
        "  y_pred = reg.predict(X_test)\n",
        "  accuracy = np.round(accuracy_score(y_test, y_pred), 2)\n",
        "  f1 = np.round(f1_score(y_test, y_pred, average='weighted'), 2)\n",
        "  recall = np.round(recall_score(y_test, y_pred, average='weighted'), 2)\n",
        "  precision = np.round(precision_score(y_test, y_pred, average='weighted'), 2)\n",
        "  actual_labels=y_test.value_counts()\n",
        "  end_time = time.time()\n",
        "  time_taken = np.round((end_time - start_time), 2)\n",
        "  y_pred = pd.DataFrame(y_pred)\n",
        "  predicted_labels=y_pred.value_counts()\n",
        "  temp_df.loc[len(temp_df)] = [dataset, dataform, X_train.shape[1], 'MLP Classifier', accuracy, f1, recall, precision,actual_labels.tolist(),predicted_labels.tolist(),time_taken]\n",
        "\n",
        "  return temp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odaNS-Lg5kui"
      },
      "source": [
        "# Dimension Reduction Through different techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFqzfqUq5lN1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle(FMatPkl)\n",
        "X=df.iloc[:,0:48]\n",
        "y=df.iloc[:,48]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "#standard scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train.shape, X_test.shape\n",
        "#PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "#LDA\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "#SVD\n",
        "svd = TruncatedSVD(n_components=int(X_train.shape[1]*0.33))\n",
        "X_train_svd = svd.fit_transform(X_train)\n",
        "X_test_svd = svd.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "OVrUvoZ060FO",
        "outputId": "cec421b5-b56a-4367-8ade-f5eeb7e8a0b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9c134d80-04a5-4db6-9bbc-f57b79ff7ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Set</th>\n",
              "      <th>Data Form</th>\n",
              "      <th>Dimensions</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Actual Labels</th>\n",
              "      <th>predicted Labels</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19028]</td>\n",
              "      <td>2.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19020, 8]</td>\n",
              "      <td>34.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>SVC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19028]</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[18993, 35]</td>\n",
              "      <td>2.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19027, 1]</td>\n",
              "      <td>27.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19016, 12]</td>\n",
              "      <td>61.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>PCA Reduced</td>\n",
              "      <td>20</td>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19010, 18]</td>\n",
              "      <td>20.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c134d80-04a5-4db6-9bbc-f57b79ff7ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c134d80-04a5-4db6-9bbc-f57b79ff7ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c134d80-04a5-4db6-9bbc-f57b79ff7ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          Data Set    Data Form Dimensions                       Model  \\\n",
              "0  features_matrix  PCA Reduced         20          LogisticRegression   \n",
              "1  features_matrix  PCA Reduced         20        KNeighborsClassifier   \n",
              "2  features_matrix  PCA Reduced         20                         SVC   \n",
              "3  features_matrix  PCA Reduced         20      DecisionTreeClassifier   \n",
              "4  features_matrix  PCA Reduced         20      RandomForestClassifier   \n",
              "5  features_matrix  PCA Reduced         20  GradientBoostingClassifier   \n",
              "6  features_matrix  PCA Reduced         20              MLP Classifier   \n",
              "\n",
              "   Accuracy  F1 Score  Recall  Precision Actual Labels predicted Labels  \\\n",
              "0       1.0       1.0     1.0        1.0   [18999, 29]          [19028]   \n",
              "1       1.0       1.0     1.0        1.0   [18999, 29]       [19020, 8]   \n",
              "2       1.0       1.0     1.0        1.0   [18999, 29]          [19028]   \n",
              "3       1.0       1.0     1.0        1.0   [18999, 29]      [18993, 35]   \n",
              "4       1.0       1.0     1.0        1.0   [18999, 29]       [19027, 1]   \n",
              "5       1.0       1.0     1.0        1.0   [18999, 29]      [19016, 12]   \n",
              "6       1.0       1.0     1.0        1.0   [18999, 29]      [19010, 18]   \n",
              "\n",
              "   Time Taken  \n",
              "0        2.23  \n",
              "1       34.41  \n",
              "2        3.63  \n",
              "3        2.65  \n",
              "4       27.18  \n",
              "5       61.98  \n",
              "6       20.86  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newPCA_df = train_test_ML2('features_matrix', 'PCA Reduced', X_train_pca, y_train, X_test_pca, y_test)\n",
        "newPCA_mlp_df = MLP('features_matrix', 'PCA Reduced', X_train_pca, y_train, X_test_pca, y_test)\n",
        "newPCA_df= newPCA_df.append(newPCA_mlp_df, ignore_index=True)\n",
        "newPCA_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "GsMIO-mS66tW",
        "outputId": "88feb796-4864-4b66-bfe8-a29e6ad46637"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff4c2d09-563c-4067-aeff-917b112d9cb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Set</th>\n",
              "      <th>Data Form</th>\n",
              "      <th>Dimensions</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Actual Labels</th>\n",
              "      <th>predicted Labels</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19026, 2]</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19019, 9]</td>\n",
              "      <td>3.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>SVC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19028]</td>\n",
              "      <td>3.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[18991, 37]</td>\n",
              "      <td>1.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19027, 1]</td>\n",
              "      <td>20.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19013, 15]</td>\n",
              "      <td>52.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>SVD Reduced</td>\n",
              "      <td>15</td>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19019, 9]</td>\n",
              "      <td>16.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff4c2d09-563c-4067-aeff-917b112d9cb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff4c2d09-563c-4067-aeff-917b112d9cb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff4c2d09-563c-4067-aeff-917b112d9cb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          Data Set    Data Form Dimensions                       Model  \\\n",
              "0  features_matrix  SVD Reduced         15          LogisticRegression   \n",
              "1  features_matrix  SVD Reduced         15        KNeighborsClassifier   \n",
              "2  features_matrix  SVD Reduced         15                         SVC   \n",
              "3  features_matrix  SVD Reduced         15      DecisionTreeClassifier   \n",
              "4  features_matrix  SVD Reduced         15      RandomForestClassifier   \n",
              "5  features_matrix  SVD Reduced         15  GradientBoostingClassifier   \n",
              "6  features_matrix  SVD Reduced         15              MLP Classifier   \n",
              "\n",
              "   Accuracy  F1 Score  Recall  Precision Actual Labels predicted Labels  \\\n",
              "0       1.0       1.0     1.0        1.0   [18999, 29]       [19026, 2]   \n",
              "1       1.0       1.0     1.0        1.0   [18999, 29]       [19019, 9]   \n",
              "2       1.0       1.0     1.0        1.0   [18999, 29]          [19028]   \n",
              "3       1.0       1.0     1.0        1.0   [18999, 29]      [18991, 37]   \n",
              "4       1.0       1.0     1.0        1.0   [18999, 29]       [19027, 1]   \n",
              "5       1.0       1.0     1.0        1.0   [18999, 29]      [19013, 15]   \n",
              "6       1.0       1.0     1.0        1.0   [18999, 29]       [19019, 9]   \n",
              "\n",
              "   Time Taken  \n",
              "0        0.66  \n",
              "1        3.03  \n",
              "2        3.75  \n",
              "3        1.66  \n",
              "4       20.91  \n",
              "5       52.91  \n",
              "6       16.40  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newSVD_df = train_test_ML2('features_matrix', 'SVD Reduced', X_train_svd, y_train, X_test_svd, y_test)\n",
        "newSVD_mlp_df = MLP('features_matrix', 'SVD Reduced', X_train_svd, y_train, X_test_svd, y_test)\n",
        "newSVD_df= newSVD_df.append(newSVD_mlp_df, ignore_index=True)\n",
        "newSVD_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "nOeFMlK07BDU",
        "outputId": "46373793-8ffd-49c9-d9a6-810f561d189f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-49dccebc-473b-4709-a171-46084004feda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Set</th>\n",
              "      <th>Data Form</th>\n",
              "      <th>Dimensions</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Actual Labels</th>\n",
              "      <th>predicted Labels</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19021, 7]</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19027, 1]</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>SVC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19028]</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[18982, 46]</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[18982, 46]</td>\n",
              "      <td>7.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19015, 13]</td>\n",
              "      <td>5.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>features_matrix</td>\n",
              "      <td>LDA Reduced</td>\n",
              "      <td>1</td>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[18999, 29]</td>\n",
              "      <td>[19028]</td>\n",
              "      <td>6.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49dccebc-473b-4709-a171-46084004feda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49dccebc-473b-4709-a171-46084004feda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49dccebc-473b-4709-a171-46084004feda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          Data Set    Data Form Dimensions                       Model  \\\n",
              "0  features_matrix  LDA Reduced          1          LogisticRegression   \n",
              "1  features_matrix  LDA Reduced          1        KNeighborsClassifier   \n",
              "2  features_matrix  LDA Reduced          1                         SVC   \n",
              "3  features_matrix  LDA Reduced          1      DecisionTreeClassifier   \n",
              "4  features_matrix  LDA Reduced          1      RandomForestClassifier   \n",
              "5  features_matrix  LDA Reduced          1  GradientBoostingClassifier   \n",
              "6  features_matrix  LDA Reduced          1              MLP Classifier   \n",
              "\n",
              "   Accuracy  F1 Score  Recall  Precision Actual Labels predicted Labels  \\\n",
              "0       1.0       1.0     1.0        1.0   [18999, 29]       [19021, 7]   \n",
              "1       1.0       1.0     1.0        1.0   [18999, 29]       [19027, 1]   \n",
              "2       1.0       1.0     1.0        1.0   [18999, 29]          [19028]   \n",
              "3       1.0       1.0     1.0        1.0   [18999, 29]      [18982, 46]   \n",
              "4       1.0       1.0     1.0        1.0   [18999, 29]      [18982, 46]   \n",
              "5       1.0       1.0     1.0        1.0   [18999, 29]      [19015, 13]   \n",
              "6       1.0       1.0     1.0        1.0   [18999, 29]          [19028]   \n",
              "\n",
              "   Time Taken  \n",
              "0        0.14  \n",
              "1        0.63  \n",
              "2        1.54  \n",
              "3        0.15  \n",
              "4        7.81  \n",
              "5        5.39  \n",
              "6        6.94  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newLDA_df = train_test_ML2('features_matrix', 'LDA Reduced', X_train_lda, y_train, X_test_lda, y_test)\n",
        "newLDA_mlp_df = MLP('features_matrix', 'LDA Reduced', X_train_lda, y_train, X_test_lda, y_test)\n",
        "newLDA_df= newLDA_df.append(newLDA_mlp_df, ignore_index=True)\n",
        "newLDA_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbm7crWgKInp"
      },
      "source": [
        "# Multi Layer Perceptron on Feature Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTR1R6_5IXcM"
      },
      "outputs": [],
      "source": [
        "def pytorch():\n",
        "  class Temp(Dataset):\n",
        "      def __init__(self, transform=None):\n",
        "          df = pd.read_pickle(FMatPkl)\n",
        "          xy= df.to_numpy()\n",
        "          \n",
        "          self.n_samples = xy.shape[0]\n",
        "          self.x_data = torch.from_numpy(df.iloc[:,0:48].values)\n",
        "          self.y_data = torch.from_numpy(df['y'].astype(int).values)\n",
        "\n",
        "          self.transform = transform\n",
        "\n",
        "      def __getitem__(self, index):\n",
        "          sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "          if self.transform:\n",
        "              sample = self.transform(sample)\n",
        "          return sample\n",
        "      def __len__(self):\n",
        "          return self.n_samples\n",
        "\n",
        "  class ToTensor:\n",
        "      # Convert ndarrays to Tensors\n",
        "      def __call__(self, sample):\n",
        "          inputs, targets = sample\n",
        "          return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "  dataset = Temp()\n",
        "  train_size = int(0.8 * len(dataset))\n",
        "  test_size = len(dataset) - train_size\n",
        "\n",
        "  trainset, testset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "  trainloader = DataLoader(dataset=trainset,batch_size=1,shuffle=True,num_workers=2)\n",
        "  testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False)\n",
        "\n",
        "  # convert to an iterator and look at one random sample\n",
        "  dataiter = iter(trainloader)\n",
        "  data=next(dataiter)\n",
        "  features ,labels= data\n",
        "\n",
        "  # Fully connected neural network with one hidden layer\n",
        "  # Hyper-parameters \n",
        "  input_size = 48\n",
        "  hidden_size = 10\n",
        "  num_classes = 2\n",
        "  num_epochs = 5\n",
        "  batch_size = 15\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  class NeuralNet(nn.Module):\n",
        "      def __init__(self, input_size, hidden_size, num_classes):\n",
        "          super(NeuralNet, self).__init__()\n",
        "          #self.input_size = input_size\n",
        "          self.l1 = nn.Linear(input_size, hidden_size*2) \n",
        "          self.l2 = nn.Linear(hidden_size*2, hidden_size)  \n",
        "          self.l3 = nn.Linear(hidden_size, num_classes) \n",
        "          \n",
        "          self.relu1 = nn.ReLU()\n",
        "          self.relu2 = nn.ReLU()\n",
        "\n",
        "          \n",
        "      def forward(self, x):\n",
        "          x = self.relu1(self.l1(x))\n",
        "          x = self.relu2(self.l2(x))\n",
        "          out = self.l3(x)\n",
        "          return out\n",
        "  model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "\n",
        "  # Train the model\n",
        "  print_every = 40\n",
        "  steps = 0\n",
        "  n_total_steps = len(trainloader)\n",
        "  for epoch in range(num_epochs):\n",
        "      running_loss = 0\n",
        "      for i, (Features, labels) in enumerate(trainloader):  \n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs =  model(Features.float())\n",
        "          loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
        "          loss = criterion(outputs, labels)\n",
        "          \n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if steps % print_every == 0:\n",
        "              #print(\"Epoch: {}/{}... \".format(epoch+1, epoch),\"Loss: {:.4f}\".format(running_loss/print_every))\n",
        "              \n",
        "              running_loss = 0\n",
        "  # Put the model in evaluation mode\n",
        "  model.eval()\n",
        "  # Test the model\n",
        "  with torch.no_grad():\n",
        "      true_labels = []\n",
        "      predicted_labels = []\n",
        "      for features, labels in testloader:\n",
        "          # Make predictions\n",
        "          outputs = model(features.float())\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "          # Append labels to list\n",
        "          true_labels.append(labels.cpu().numpy())\n",
        "          predicted_labels.append(predicted.cpu().numpy())\n",
        "\n",
        "      # Flatten the lists\n",
        "      true_labels = [label for sublist in true_labels for label in sublist]\n",
        "      predicted_labels = [label for sublist in predicted_labels for label in sublist]\n",
        "\n",
        "      # Calculate F1 score\n",
        "      f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "      print('F1 score: {:.4f}'.format(f1))\n",
        "      # Calculate Accuracy\n",
        "      accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "      recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "      precision =precision_score(true_labels, predicted_labels, average='weighted')\n",
        "      print('recall: {:.4f}'.format(recall))\n",
        "      print('precision: {:.4f}'.format(precision))\n",
        "      print('accuracy: {:.4f}'.format(accuracy))\n",
        "      \n",
        "      conf_matrix = confusion_matrix(true_labels ,predicted_labels)\n",
        "      print(\"Confusion Matrix of the Test Set\")\n",
        "      print(\"-----------\")\n",
        "      print(conf_matrix)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PFXllLKPF54"
      },
      "source": [
        "#IND2new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAFSm0qFNzUd",
        "outputId": "e61770a1-670f-4181-9378-0d83d008f5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.9656\n",
            "recall: 0.9756\n",
            "precision: 0.9762\n",
            "accuracy: 0.9756\n",
            "Confusion Matrix of the Test Set\n",
            "-----------\n",
            "[[1197    0]\n",
            " [  30    3]]\n"
          ]
        }
      ],
      "source": [
        "pytorch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkmQCl9gO5Rx"
      },
      "source": [
        "#COM_NEW "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogl99uVSIXfM",
        "outputId": "4c626a3b-ed9b-4f0a-a3f0-8804807de2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.9981\n",
            "recall: 0.9987\n",
            "precision: 0.9975\n",
            "accuracy: 0.9987\n",
            "Confusion Matrix of the Test Set\n",
            "-----------\n",
            "[[19004     0]\n",
            " [   24     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "pytorch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Embedding"
      ],
      "metadata": {
        "id": "r6hHIVkHxSss"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6c4u4p1ExQaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnKaTNFKSAj"
      },
      "source": [
        "# Hetero Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSiSl4v8_hUm"
      },
      "outputs": [],
      "source": [
        "def HetroData():\n",
        "\n",
        "  data = HeteroData()\n",
        "  pubCent = pd.read_pickle(pubCentPkl)\n",
        "  venCent = pd.read_pickle(venCentPkl)\n",
        "  autCent = pd.read_pickle(autCentPkl)\n",
        "  autCOCI = pd.read_pickle(autCitNet)\n",
        "\n",
        "  COCI = pd.read_pickle(citNet)\n",
        "  DF = pd.read_pickle(metadata).reset_index()\n",
        "  pubCN = COCI.drop(columns=['Venue_citing','Venue_cited','Title_citing','Title_cited'], axis=1)\n",
        "  venCN = COCI.drop(columns=['citing','cited','Title_citing','Title_cited'], axis=1)\n",
        "  autCN = autCOCI.drop(columns=['Venue_citing','Venue_cited','citing','cited'], axis=1)\n",
        "  autCN = autCN.drop_duplicates()\n",
        "  autCN.rename(columns = {'autID_citing':'citing','autID_cited':'cited'}, inplace = True)\n",
        "  pubCent = pubCent.reset_index()\n",
        "  pubCent['index']=pubCent.index\n",
        "  pubCent = pubCent.set_index('Publication').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  venCent = venCent.reset_index()\n",
        "  venCent['index']=venCent.index\n",
        "  venCent = venCent.set_index('Venue').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  autCent = autCent.reset_index()\n",
        "  autCent['index']=autCent.index\n",
        "  autCent = autCent.set_index('Author').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  autCent = autCent.reset_index()\n",
        "  autCN = autCN.merge(autCent, left_on='citing', right_index=True)\n",
        "  autCN = autCN.merge(autCent, left_on='cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  pubCN = pubCN.merge(pubCent, left_on='citing', right_index=True)\n",
        "  pubCN = pubCN.merge(pubCent, left_on='cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  venCN = venCN.merge(venCent, left_on='Venue_citing', right_index=True)\n",
        "  venCN = venCN.merge(venCent, left_on='Venue_cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  DF_Author = DF.copy()\n",
        "\n",
        "  DF_Author = DF_Author.merge(pubCent, left_on='DOI', right_index=True)\n",
        "  DF_Author = DF_Author.merge(autCent, left_on='Author', right_on='Author', suffixes=['_DOI','_Author'])\n",
        "  DF_Author = DF_Author.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_DOI').first().reset_index()\n",
        "\n",
        "\n",
        "  #1st MetaPath\n",
        "  src = list(DF_Author.index_Author)\n",
        "  dst = list(DF_Author.index_DOI)\n",
        "  edge_index = torch.tensor([src, dst])\n",
        "  data['Author', 'writes', 'Publication'].edge_index = edge_index\n",
        "\n",
        "  #2nd MetaPath\n",
        "  src = list(pubCN.index_citing)\n",
        "  dst = list(pubCN.index_cited)\n",
        "  edge_index = torch.tensor([src, dst])\n",
        "  data['Publication', 'cite', 'Publication'].edge_index = edge_index\n",
        "\n",
        "\n",
        "  #3rd MetaPath\n",
        "  DF = DF.merge(pubCent, left_on='DOI', right_index=True)\n",
        "  DF = DF.merge(venCent, left_on='Venue', right_index=True, suffixes=['_DOI','_Venue'])\n",
        "  DF = DF.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_DOI').first().reset_index()\n",
        "  src = list(DF.index_DOI)\n",
        "  dst = list(DF.index_Venue)\n",
        "  edge_index = torch.tensor([src, dst])#.t().contiguous()\n",
        "  data['Publication', 'in', 'Venue'].edge_index = edge_index\n",
        "\n",
        "\n",
        "  #4th MetaPath\n",
        "  DF = pd.read_pickle(metadata).reset_index()\n",
        "  DF = DF.merge(venCent, left_on='Venue', right_index=True)\n",
        "  DF = DF.merge(autCent, left_on='Author', right_on='Author', suffixes=['_Venue','_Author'])\n",
        "  DF = DF.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_Venue').first().reset_index()\n",
        "  src = list(DF.index_Venue)\n",
        "  dst = list(DF.index_Author)\n",
        "  edge_index = torch.tensor([src, dst])#.t().contiguous()\n",
        "  data['Venue', 'has', 'Author'].edge_index = edge_index\n",
        "  print(data)\n",
        "  return data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metapaths**"
      ],
      "metadata": {
        "id": "6Dn9pi9EOTnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hetrodata  =  HetroData()\n",
        "def Metapath(hetrodata):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  device = \"cpu\"\n",
        "\n",
        "  metapath = [\n",
        "    ('Author', 'writes', 'Publication'),\n",
        "    ('Publication', 'cite', 'Publication'),\n",
        "    ('Publication', 'in', 'Venue'),\n",
        "    ('Venue', 'has', 'Author')\n",
        "  ]\n",
        "  model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
        "                      metapath=metapath, walk_length=50, context_size=3,\n",
        "                      walks_per_node=3, num_negative_samples=1,\n",
        "                      sparse=True).to(device)\n",
        "\n",
        "  loader = model.loader(batch_size=128, shuffle=True, num_workers=3)\n",
        "\n",
        "  for idx, (pos_rw, neg_rw) in enumerate(loader):\n",
        "      if idx == 10: break\n",
        "      print(idx, pos_rw.shape, neg_rw.shape)\n",
        "\n",
        "  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "  def train(epoch, log_steps=50, eval_steps=100):\n",
        "      model.train()\n",
        "\n",
        "      total_loss = 0\n",
        "      for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "          optimizer.zero_grad()\n",
        "          loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          if (i + 1) % log_steps == 0:\n",
        "              print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                    f'Loss: {total_loss / log_steps:.4f}'))\n",
        "              total_loss = 0\n",
        "\n",
        "          if (i + 1) % eval_steps == 0:\n",
        "              acc = test()\n",
        "              print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                    f'Acc: {acc:.4f}'))\n",
        "  def test(train_ratio=0.3):\n",
        "      model.eval()\n",
        "      z = model('Author', batch=data.y_index_dict['Author'])\n",
        "      \n",
        "      y = data.y_dict['Author']\n",
        "\n",
        "      perm = torch.randperm(z.size(0))\n",
        "      train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "      test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "      return model.test(z[train_perm], y[train_perm], z[test_perm],\n",
        "                        y[test_perm], max_iter=1500)\n",
        "  for epoch in range(1, 6):\n",
        "\n",
        "    train(epoch)\n",
        "    print('trian')\n",
        "    #  acc = test()\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "  loaded_model = MetaPath2Vec(data.edge_index_dict, \n",
        "                      embedding_dim=128,\n",
        "                      metapath=metapath,\n",
        "                      walk_length=5, \n",
        "                      context_size=3,\n",
        "                      walks_per_node=3,\n",
        "                      num_negative_samples=1,\n",
        "                      sparse=True\n",
        "                      ).to(device)\n",
        "\n",
        "  print(\"embeddings:\",model.embedding.weight)"
      ],
      "metadata": {
        "id": "ejv_1tmoOTAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-QX4jSKeD8"
      },
      "source": [
        "# Graph Convolutional Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS5wUlqJIXl_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Crossref Data/Experiments/IND2new/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKYwc7HcIXok"
      },
      "outputs": [],
      "source": [
        "def load_edge():\n",
        "  COCI = pd.read_pickle(\"1985COCI2015.pkl\")\n",
        "  pubCN = COCI.drop(columns=['Venue_citing','Venue_cited','Title_citing','Title_cited'], axis=1)\n",
        "  pubCent = pd.read_pickle(\"pubCent.pkl\");\n",
        "  pubCent = pubCent.reset_index()\n",
        "  pubCent['index']=pubCent.index\n",
        "  pubCent = pubCent.set_index('Publication').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  pubCN = pubCN.merge(pubCent, left_on='citing', right_index=True)\n",
        "  pubCN = pubCN.merge(pubCent, left_on='cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  src = list(pubCN.index_citing)\n",
        "  dst = list(pubCN.index_cited)\n",
        "  edge_index = torch.tensor([src, dst])\n",
        "  return edge_index\n",
        "\n",
        "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
        "  R=torch.zeros((doi_cited,doi_citing))\n",
        "  for i in range(len(input_edge_index[0])):\n",
        "    row_idx=input_edge_index[0][i]\n",
        "    col_idx=input_edge_index[1][i]\n",
        "    R[row_idx][col_idx]=1\n",
        "\n",
        "  R_transpose=torch.transpose(R,0,1)\n",
        "  adj_mat=torch.zeros((doi_cited+doi_citing,doi_cited+doi_citing))\n",
        "  adj_mat[:doi_cited,doi_cited:]=R.clone()\n",
        "  adj_mat[doi_cited : ,: doi_cited]=R.transpose.clone()\n",
        "  adj_mat_coo=adj_mat.to_sparse_coo()\n",
        "  adj_mat_coo=adj_mat_coo.indices()\n",
        "  return adj_mat_coo\n",
        "\n",
        "def sample_mini_bat(batch_size,edge_index):\n",
        "  edges=structured_negative_sampling(edge_index)\n",
        "  edges=torch.stack(edges,dim=0)\n",
        "\n",
        "  indices=random.choices([ i for i in range(edges[0].shape[0])],k=batch_size)\n",
        "\n",
        "  batch=edges[:,indices]\n",
        "\n",
        "  cited_indices,pos_item_indices,neg_item_indices=batch[0],batch[1],batch[2]\n",
        "  return cited_indices,pos_item_indices,neg_item_indices\n",
        "\n",
        "\n",
        "from torch_geometric.nn.conv.supergat_conv import add_self_loops\n",
        "class LigthGCN(MessagePassing):\n",
        "    def __init__(self,doi_cited,doi_citing,embedding_dim=64,K=3,add_self_loop=False):\n",
        "      super().__init__()\n",
        "      self.doi_cited=doi_cited\n",
        "      self.doi_citing=doi_citing\n",
        "      self.embedding_dim=embedding_dim\n",
        "      self.K=K\n",
        "      self.add_self_loop=add_self_loops\n",
        "\n",
        "      self.cited_emb=nn.Embedding(num_embeddings=self.doi_cited,embedding_dim=self.embedding_dim)\n",
        "      self.citing_emb=nn.Embedding(num_embeddings=self.doi_citing,embedding_dim=self.embedding_dim)\n",
        "\n",
        "      nn.init.normal_(self.cited_emb.weight,std=0.1)\n",
        "      nn.init.normal_(self.citing_emb.weight,std=0.1)\n",
        "\n",
        "    def forward(self,edge_index:Tensor):\n",
        "\n",
        "\n",
        "      edge_index_norm=gcn_norm(edge_index=edge_index,add_self_loops=add_self_loops)\n",
        "\n",
        "      emb_0=torch.cat([self.cited_emb.weight,self.citing_emb.weight])\n",
        "      embs=[emb_0] #save the layer0 embedding to the embedding list\n",
        "\n",
        "      #emb_k is the emb that we are actually going to push it through the graph layers\n",
        "      emb_k=emb_0\n",
        "\n",
        "\n",
        "      # push the embedding of all citing and cited nodes through the graph Model k times.\n",
        "      # Here K is the number of Layers\n",
        "      for i in range(self.K):\n",
        "        emb_k=self.propagate(edge_index=edge_index_norm[0],x=emb_k,norm=edge_index_norm[1])\n",
        "        embs.append(emb_k)\n",
        "\n",
        "\n",
        "      # the stacked embs is a list of embeddings matrix at each layer\n",
        "      # its of a shape n_nodes x (n_layers + 1) x emb_vector_len\n",
        "\n",
        "      embs=torch.stack(embs,dim=1)\n",
        "\n",
        "      emb_final =torch.mean(embs,dim=1)   #it is essentialy just multiplying\n",
        "\n",
        "      citing_emb_final,cited_emb_final=torch.split(emb_final,[self.doi_cited,self.doi_citing])\n",
        "\n",
        "      return  citing_emb_final,self.citing_emb.weight,cited_emb_final,self.cited_emb.weight\n",
        "\n",
        "    def message(self,x_j,norm):\n",
        "\n",
        "      #x_j is the shape of: edge_index_len X emb_vector_len\n",
        "\n",
        "      # x_j is basically he embedding of all the neighbour based on the src_list in the coo edge index\n",
        "\n",
        "      return norm.view(-1,1)* x_j\n",
        "\n",
        "layers=3\n",
        "model=LigthGCN(doi_cited=doi_cited,doi_citing=doi_citing,K=layers)\n",
        "def bpr_loss(citing_emb_final,\n",
        "             citing_emb_0,\n",
        "             pos_cited_emb_final,\n",
        "             pos_cited_emb_0,\n",
        "             neg_cited_emb_final,\n",
        "             neg_cited_emb_0,\n",
        "             lambda_val\n",
        "             ):\n",
        "  reg_loss=lambda_val *(citing_emb_0.norm(2).pow(2)+\n",
        "                        pos_cited_emb_0.norm(2).pow(2)+\n",
        "                        neg_cited_emb_0.norm(2).pow(2)) #L2 Loss\n",
        "\n",
        "  pos_scores=torch.mul(citing_emb_final,pos_cited_emb_final)\n",
        "  pos_scores=torch.sum(pos_scores,dim=1)\n",
        "  neg_scores=torch.mul(citing_emb_final,neg_cited_emb_final)\n",
        "  neg_scores=torch.sum(neg_scores,dim=1)\n",
        "\n",
        "  bpr_loss= -torch.mean(torch.nn.functional.softplus(pos_scores- neg_scores))\n",
        "\n",
        "  loss=bpr_loss + reg_loss\n",
        "\n",
        "  return loss\n",
        "def get_citing_positive_items(edge_index):\n",
        "\n",
        "  citing_pos_items={}\n",
        "\n",
        "  for i in range(edge_index.shape[1]):\n",
        "    citing=edge_index[0][i].item()\n",
        "    cited=edge_index[1][i].item()\n",
        "\n",
        "    if citing not in citing_pos_items:\n",
        "      citing_pos_items[citing] = []\n",
        "    citing_pos_items[citing].append(cited)\n",
        "\n",
        "  return citing_pos_items\n",
        "  methapath(data)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}