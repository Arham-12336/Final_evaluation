{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arham-12336/Final_evaluation/blob/main/MetaPath2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niD5WzT0ONr-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "\n",
        "!pip install pyg-lib\n",
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "import os\n",
        "import torch\n",
        "from torch_geometric.nn import MetaPath2Vec\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Kl35d_mTOXKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubCent = pd.read_pickle(pubCentPkl)\n",
        "venCent = pd.read_pickle(venCentPkl)\n",
        "autCent = pd.read_pickle(autCentPkl)\n",
        "autCOCI = pd.read_pickle(autCitNet)"
      ],
      "metadata": {
        "id": "UuwAWE4UbKeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HetroData():\n",
        "\n",
        "  data = HeteroData()\n",
        "  pubCent = pd.read_pickle(pubCentPkl)\n",
        "  venCent = pd.read_pickle(venCentPkl)\n",
        "  autCent = pd.read_pickle(autCentPkl)\n",
        "  autCOCI = pd.read_pickle(autCitNet)\n",
        "  data['Publication'].x = torch.tensor(pubCent.values)\n",
        "\n",
        "  data['Venue'].x = torch.tensor(venCent.values)\n",
        "\n",
        "  data['Author'].x = torch.tensor(autCent.values)\n",
        "\n",
        "  COCI = pd.read_pickle(citNet)\n",
        "  DF = pd.read_pickle(metadata).reset_index()\n",
        "  pubCN = COCI.drop(columns=['Venue_citing','Venue_cited','Title_citing','Title_cited'], axis=1)\n",
        "  venCN = COCI.drop(columns=['citing','cited','Title_citing','Title_cited'], axis=1)\n",
        "  autCN = autCOCI.drop(columns=['Venue_citing','Venue_cited','citing','cited'], axis=1)\n",
        "  autCN = autCN.drop_duplicates()\n",
        "  autCN.rename(columns = {'autID_citing':'citing','autID_cited':'cited'}, inplace = True)\n",
        "  pubCent = pubCent.reset_index()\n",
        "  pubCent['index']=pubCent.index\n",
        "  pubCent = pubCent.set_index('Publication').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  venCent = venCent.reset_index()\n",
        "  venCent['index']=venCent.index\n",
        "  venCent = venCent.set_index('Venue').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  autCent = autCent.reset_index()\n",
        "  autCent['index']=autCent.index\n",
        "  autCent = autCent.set_index('Author').drop(columns=['IN','OUT','ACC','Hub','Auth','PR','BC','CC'], axis=1)\n",
        "  autCent = autCent.reset_index()\n",
        "  autCN = autCN.merge(autCent, left_on='citing', right_index=True)\n",
        "  autCN = autCN.merge(autCent, left_on='cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  pubCN = pubCN.merge(pubCent, left_on='citing', right_index=True)\n",
        "  pubCN = pubCN.merge(pubCent, left_on='cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  venCN = venCN.merge(venCent, left_on='Venue_citing', right_index=True)\n",
        "  venCN = venCN.merge(venCent, left_on='Venue_cited', right_index=True, suffixes=['_citing','_cited'])\n",
        "  DF_Author = DF.copy()\n",
        "\n",
        "  DF_Author = DF_Author.merge(pubCent, left_on='DOI', right_index=True)\n",
        "  DF_Author = DF_Author.merge(autCent, left_on='Author', right_on='Author', suffixes=['_DOI','_Author'])\n",
        "  DF_Author = DF_Author.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_DOI').first().reset_index()\n",
        "\n",
        "\n",
        "  #1st MetaPath\n",
        "  src = list(DF_Author.index_Author)\n",
        "  dst = list(DF_Author.index_DOI)\n",
        "  edge_index = torch.tensor([src, dst])\n",
        "  data['Author', 'writes', 'Publication'].edge_index = edge_index\n",
        "\n",
        "  #2nd MetaPath\n",
        "  src = list(pubCN.index_citing)\n",
        "  dst = list(pubCN.index_cited)\n",
        "  edge_index = torch.tensor([src, dst])\n",
        "  data['Publication', 'cite', 'Publication'].edge_index = edge_index\n",
        "\n",
        "\n",
        "  #3rd MetaPath\n",
        "  DF = DF.merge(pubCent, left_on='DOI', right_index=True)\n",
        "  DF = DF.merge(venCent, left_on='Venue', right_index=True, suffixes=['_DOI','_Venue'])\n",
        "  DF = DF.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_DOI').first().reset_index()\n",
        "  src = list(DF.index_DOI)\n",
        "  dst = list(DF.index_Venue)\n",
        "  edge_index = torch.tensor([src, dst])#.t().contiguous()\n",
        "  data['Publication', 'in', 'Venue'].edge_index = edge_index\n",
        "\n",
        "\n",
        "  #4th MetaPath\n",
        "  DF = pd.read_pickle(metadata).reset_index()\n",
        "  DF = DF.merge(venCent, left_on='Venue', right_index=True)\n",
        "  DF = DF.merge(autCent, left_on='Author', right_on='Author', suffixes=['_Venue','_Author'])\n",
        "  DF = DF.drop(columns=['DOI','Title','Venue','Year','Author'],axis=1).groupby('index_Venue').first().reset_index()\n",
        "  src = list(DF.index_Venue)\n",
        "  dst = list(DF.index_Author)\n",
        "  edge_index = torch.tensor([src, dst])#.t().contiguous()\n",
        "  data['Venue', 'has', 'Author'].edge_index = edge_index\n",
        "\n",
        "  \n",
        "  # print(data)\n",
        "  return data"
      ],
      "metadata": {
        "id": "6TinbyYwU66J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = HetroData()\n",
        "Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULkS8KTxiYa4",
        "outputId": "de565f2e-0157-46f1-b518-781b261309ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mPublication\u001b[0m={ x=[6662, 8] },\n",
              "  \u001b[1mVenue\u001b[0m={ x=[2290, 8] },\n",
              "  \u001b[1mAuthor\u001b[0m={ x=[11884, 8] },\n",
              "  \u001b[1m(Author, writes, Publication)\u001b[0m={ edge_index=[2, 6219] },\n",
              "  \u001b[1m(Publication, cite, Publication)\u001b[0m={ edge_index=[2, 15089] },\n",
              "  \u001b[1m(Publication, in, Venue)\u001b[0m={ edge_index=[2, 6354] },\n",
              "  \u001b[1m(Venue, has, Author)\u001b[0m={ edge_index=[2, 2265] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hetrodata  = torch.load('HeteroData.pt')\n",
        "def Metapath(data):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  device = \"cpu\"\n",
        "\n",
        "  metapath = [\n",
        "    ('Author', 'writes', 'Publication'),\n",
        "    ('Publication', 'cite', 'Publication'),\n",
        "    ('Publication', 'in', 'Venue'),\n",
        "    ('Venue', 'has', 'Author')\n",
        "  ]\n",
        "  model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
        "                      metapath=metapath, walk_length=50, context_size=3,\n",
        "                      walks_per_node=3, num_negative_samples=1,\n",
        "                      sparse=True).to(device)\n",
        "\n",
        "  loader = model.loader(batch_size=128, shuffle=True, num_workers=3)\n",
        "\n",
        "  for idx, (pos_rw, neg_rw) in enumerate(loader):\n",
        "      if idx == 10: break\n",
        "      print(idx, pos_rw.shape, neg_rw.shape)\n",
        "\n",
        "  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "  def train(epoch, log_steps=50, eval_steps=100):\n",
        "      model.train()\n",
        "\n",
        "      total_loss = 0\n",
        "      for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "          optimizer.zero_grad()\n",
        "          loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          if (i + 1) % log_steps == 0:\n",
        "              print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                    f'Loss: {total_loss / log_steps:.4f}'))\n",
        "              total_loss = 0\n",
        "\n",
        "          if (i + 1) % eval_steps == 0:\n",
        "              acc = test()\n",
        "              print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                    f'Acc: {acc:.4f}'))\n",
        "  def test(train_ratio=0.3):\n",
        "      model.eval()\n",
        "      z = model('Author', batch=data.y_index_dict['Author'])\n",
        "      \n",
        "      y = data.y_dict['Author']\n",
        "\n",
        "      perm = torch.randperm(z.size(0))\n",
        "      train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "      test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "      return model.test(z[train_perm], y[train_perm], z[test_perm],\n",
        "                        y[test_perm], max_iter=1500)\n",
        "  for epoch in range(1, 6):\n",
        "\n",
        "    train(epoch)\n",
        "    print('trian')\n",
        "    #  acc = test()\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "  loaded_model = MetaPath2Vec(data.edge_index_dict, \n",
        "                      embedding_dim=128,\n",
        "                      metapath=metapath,\n",
        "                      walk_length=5, \n",
        "                      context_size=3,\n",
        "                      walks_per_node=3,\n",
        "                      num_negative_samples=1,\n",
        "                      sparse=True\n",
        "                      ).to(device)\n",
        "\n",
        "  print(\"embeddings:\",model.embedding.weight)"
      ],
      "metadata": {
        "id": "qZFz7l3mY5ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Matapath_Result  = Metapath(Data)\n",
        "Matapath_Result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7NgrFpsaDSL",
        "outputId": "b8190f72-6db6-4cd8-fc55-a0bad5319ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "1 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "2 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "3 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "4 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "5 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "6 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "7 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "8 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "9 torch.Size([18816, 3]) torch.Size([18816, 3])\n",
            "Epoch: 1, Step: 00050/93, Loss: 5.6696\n",
            "trian\n",
            "Epoch: 1\n",
            "Epoch: 2, Step: 00050/93, Loss: 4.4610\n",
            "trian\n",
            "Epoch: 2\n",
            "Epoch: 3, Step: 00050/93, Loss: 3.5327\n",
            "trian\n",
            "Epoch: 3\n",
            "Epoch: 4, Step: 00050/93, Loss: 2.7133\n",
            "trian\n",
            "Epoch: 4\n",
            "Epoch: 5, Step: 00050/93, Loss: 2.0012\n",
            "trian\n",
            "Epoch: 5\n",
            "embeddings: Parameter containing:\n",
            "tensor([[-0.7514, -0.9259,  1.0463,  ...,  0.2749,  0.9522,  0.8225],\n",
            "        [-1.2731,  0.2759, -0.4865,  ...,  0.3546,  1.8139, -0.6559],\n",
            "        [-0.6534, -0.2968,  0.8695,  ..., -0.8537,  0.3917, -0.1902],\n",
            "        ...,\n",
            "        [-0.6663, -0.2820, -0.5791,  ...,  0.7419,  0.8439,  0.7090],\n",
            "        [ 0.5183, -0.9961,  0.0826,  ..., -0.1160,  0.3720, -0.0304],\n",
            "        [-0.4283, -0.6527,  0.2197,  ..., -0.1768,  0.5264,  0.1755]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}